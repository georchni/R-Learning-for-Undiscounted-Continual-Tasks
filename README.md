# R-Learning-for-Undiscounted-Continual-Tasks
The following algorithm is a Reinforcement Learning implementation for optimization of the control policy on a production system. 
"R-learning is an off-policy control method for the advanced version of the reinforcement learning problem in which one neither discounts nor divides 
experience into distinct episodes with finite returns. In this case one seeks to obtain the maximum reward per-time-step" [1].
The algorithm could be considered as a variation (more like an of-policy SARSA) of the Q - learning and SARSA (State-Action-Reward-State-Action) algorithm 
adapted to a 2 variable state dependent strategy. It can be used for motivation rather than for execution.  

The discrete event simulation model of the production system is not given here due to shared copyrights.

The research conducted as part of my engineering diploma thesis.
The  link for the publication: https://www.tandfonline.com/doi/abs/10.1080/21681015.2019.1647301

[1]: Sutton, R. S., & Barto, A. G. (1998). Reinforcement learning: An introduction. Cambridge, Mass: MIT Press.
